<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · SolverBenchmark.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="SolverBenchmark.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SolverBenchmark.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Tables-1"><span>Tables</span></a></li><li><a class="tocitem" href="#PkgBenchmark-1"><span>PkgBenchmark</span></a></li><li><a class="tocitem" href="#Profiles-1"><span>Profiles</span></a></li><li><a class="tocitem" href="#Formatting-1"><span>Formatting</span></a></li></ul></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/SolverBenchmark.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-1"><a class="docs-heading-anchor" href="#API-1">API</a><a class="docs-heading-anchor-permalink" href="#API-1" title="Permalink"></a></h1><ul><li><a href="#API-1">API</a></li><ul><li><a href="#Tables-1">Tables</a></li><li><a href="#PkgBenchmark-1">PkgBenchmark</a></li><li><a href="#Profiles-1">Profiles</a></li><li><a href="#Formatting-1">Formatting</a></li></ul></ul><h2 id="Tables-1"><a class="docs-heading-anchor" href="#Tables-1">Tables</a><a class="docs-heading-anchor-permalink" href="#Tables-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.format_table" href="#SolverBenchmark.format_table"><code>SolverBenchmark.format_table</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">format_table(df, formatter, kwargs...)</code></pre><p>Format the data frame into a table using <code>formatter</code>. Used by other table functions.</p><p>Inputs:</p><ul><li><code>df::DataFrame</code>: Dataframe of a solver. Each row is a problem.</li><li><code>formatter::Function</code>: A function that formats its input according to its type. See <code>LTXformat</code> or <code>MDformat</code> for examples.</li></ul><p>Keyword arguments:</p><ul><li><p><code>cols::Array{Symbol}</code>: Which columns of the <code>df</code>. Defaults to using all columns;</p></li><li><p><code>ignore_missing_cols::Bool</code>: If <code>true</code>, filters out the columns in <code>cols</code> that don&#39;t exist in the data frame. Useful when creating tables for solvers in a loop where one solver has a column the other doesn&#39;t. If <code>false</code>, throws <code>BoundsError</code> in that situation.</p></li><li><p><code>fmt_override::Dict{Symbol,Function}</code>: Overrides format for a specific column, such as</p><p>fmt_override=Dict(:name =&gt; x-&gt;@sprintf(&quot;<strong>%-10s</strong>&quot;, x))</p></li><li><p><code>hdr_override::Dict{Symbol,String}</code>: Overrides header names, such as <code>hdr_override=Dict(:name =&gt; &quot;Name&quot;)</code>.</p></li></ul><p>Outputs:</p><ul><li><code>header::Array{String,1}</code>: header vector.</li><li><code>table::Array{String,2}</code>: formatted table.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.join" href="#Base.join"><code>Base.join</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">df = join(stats, cols; kwargs...)</code></pre><p>Join a dictionary of DataFrames given by <code>stats</code>. Column <code>:id</code> is required in all DataFrames. The resulting DataFrame will have column <code>id</code> and all columns <code>cols</code> for each solver.</p><p>Inputs:</p><ul><li><code>stats::Dict{Symbol,DataFrame}</code>: Dictionary of DataFrames per solver. Each key is a different solver;</li><li><code>cols::Array{Symbol}</code>: Which columns of the DataFrames.</li></ul><p>Keyword arguments:</p><ul><li><code>invariant_cols::Array{Symbol,1}</code>: Invariant columns to be added, i.e., columns that don&#39;t change depending on the solver (such as name of problem, number of variables, etc.);</li><li><code>hdr_override::Dict{Symbol,String}</code>: Override header names.</li></ul><p>Output:</p><ul><li><code>df::DataFrame</code>: Resulting dataframe.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.latex_table" href="#SolverBenchmark.latex_table"><code>SolverBenchmark.latex_table</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">latex_table(io, df, kwargs...)</code></pre><p>Create a latex longtable of a DataFrame using LaTeXTabulars, and format the output for a publication-ready table.</p><p>Inputs:</p><ul><li><p><code>io::IO</code>: where to send the table, e.g.:</p><pre><code class="language-none">open(&quot;file.tex&quot;, &quot;w&quot;) do io
  latex_table(io, df)
end</code></pre><p>If left out, <code>io</code> defaults to <code>stdout</code>.</p></li><li><p><code>df::DataFrame</code>: Dataframe of a solver. Each row is a problem.</p></li></ul><p>Keyword arguments:</p><ul><li><p><code>cols::Array{Symbol}</code>: Which columns of the <code>df</code>. Defaults to using all columns;</p></li><li><p><code>ignore_missing_cols::Bool</code>: If <code>true</code>, filters out the columns in <code>cols</code> that don&#39;t exist in the data frame. Useful when creating tables for solvers in a loop where one solver has a column the other doesn&#39;t. If <code>false</code>, throws <code>BoundsError</code> in that situation.</p></li><li><p><code>fmt_override::Dict{Symbol,Function}</code>: Overrides format for a specific column, such as</p><pre><code class="language-none">fmt_override=Dict(:name =&gt; x-&gt;@sprintf(&quot;\textbf{%s}&quot;, x) |&gt; safe_latex_AbstractString)`</code></pre></li><li><p><code>hdr_override::Dict{Symbol,String}</code>: Overrides header names, such as <code>hdr_override=Dict(:name =&gt; &quot;Name&quot;)</code>, where LaTeX escaping should be used if necessary.</p></li></ul><p>We recommend using the <code>safe_latex_foo</code> functions when overriding formats, unless you&#39;re sure you don&#39;t need them.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.markdown_table" href="#SolverBenchmark.markdown_table"><code>SolverBenchmark.markdown_table</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">markdown_table(io, df, kwargs...)</code></pre><p>Create a markdown table from a DataFrame using PrettyTables and format the output.</p><p>Inputs:</p><ul><li><p><code>io::IO</code>: where to send the table, e.g.:</p><pre><code class="language-none">open(&quot;file.md&quot;, &quot;w&quot;) do io
  markdown_table(io, df)
end</code></pre><p>If left out, <code>io</code> defaults to <code>stdout</code>.</p></li><li><p><code>df::DataFrame</code>: Dataframe of a solver. Each row is a problem.</p></li></ul><p>Keyword arguments:</p><ul><li><p><code>cols::Array{Symbol}</code>: Which columns of the <code>df</code>. Defaults to using all columns;</p></li><li><p><code>ignore_missing_cols::Bool</code>: If <code>true</code>, filters out the columns in <code>cols</code> that don&#39;t exist in the data frame. Useful when creating tables for solvers in a loop where one solver has a column the other doesn&#39;t. If <code>false</code>, throws <code>BoundsError</code> in that situation.</p></li><li><p><code>fmt_override::Dict{Symbol,Function}</code>: Overrides format for a specific column, such as</p><p>fmt_override=Dict(:name =&gt; x-&gt;@sprintf(&quot;<strong>%-10s</strong>&quot;, x))</p></li><li><p><code>hdr_override::Dict{Symbol,String}</code>: Overrides header names, such as <code>hdr_override=Dict(:name =&gt; &quot;Name&quot;)</code>.</p></li></ul></div></section></article><h2 id="PkgBenchmark-1"><a class="docs-heading-anchor" href="#PkgBenchmark-1">PkgBenchmark</a><a class="docs-heading-anchor-permalink" href="#PkgBenchmark-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.bmark_results_to_dataframes" href="#SolverBenchmark.bmark_results_to_dataframes"><code>SolverBenchmark.bmark_results_to_dataframes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stats = bmark_results_to_dataframes(results)</code></pre><p>Convert <code>PkgBenchmark</code> results to a dictionary of <code>DataFrame</code>s.</p><p>Inputs:</p><ul><li><code>results::BenchmarkResults</code>: the result of <code>PkgBenchmark.benchmarkpkg()</code></li></ul><p>Output:</p><ul><li><code>stats::Dict{Symbol,DataFrame}</code>: a dictionary of <code>DataFrame</code>s containing the   benchmark results per solver.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.judgement_results_to_dataframes" href="#SolverBenchmark.judgement_results_to_dataframes"><code>SolverBenchmark.judgement_results_to_dataframes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stats = judgement_results_to_dataframes(judgement)</code></pre><p>Convert <code>BenchmarkJudgement</code> results to a dictionary of <code>DataFrame</code>s.</p><p>Inputs:</p><ul><li><p><code>judgement::BenchmarkJudgement</code>: the result of, e.g.,</p><pre><code class="language-none">commit = benchmarkpkg(mypkg)  # benchmark a commit or pull request
master = benchmarkpkg(mypkg, &quot;master&quot;)  # baseline benchmark
judgement = judge(commit, master)</code></pre></li></ul><p>Output:</p><ul><li><code>stats::Dict{Symbol,DataFrame}</code>: a dictionary of <code>DataFrame</code>s containing the   target and baseline benchmark results.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.to_gist" href="#SolverBenchmark.to_gist"><code>SolverBenchmark.to_gist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">posted_gist = to_gist(results, p)</code></pre><p>Create and post a gist with the benchmark results and performance profiles.</p><p>Inputs:</p><ul><li><code>results::BenchmarkResults</code>: the result of <code>PkgBenchmark.benchmarkpkg()</code></li><li><code>p</code>:: the result of <code>profile_solvers()</code>.</li></ul><p>Output:</p><ul><li>the return value of GitHub.jl&#39;s <code>create_gist()</code>.</li></ul></div></section><section><div><pre><code class="language-none">posted_gist = to_gist(results)</code></pre><p>Create and post a gist with the benchmark results and performance profiles.</p><p>Inputs:</p><ul><li><code>results::BenchmarkResults</code>: the result of <code>PkgBenchmark.benchmarkpkg()</code></li></ul><p>Output:</p><ul><li>the return value of GitHub.jl&#39;s <code>create_gist()</code>.</li></ul></div></section></article><h2 id="Profiles-1"><a class="docs-heading-anchor" href="#Profiles-1">Profiles</a><a class="docs-heading-anchor-permalink" href="#Profiles-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="BenchmarkProfiles.performance_profile" href="#BenchmarkProfiles.performance_profile"><code>BenchmarkProfiles.performance_profile</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">performance_profile(stats, cost)</code></pre><p>Produce a performance profile comparing solvers in <code>stats</code> using the <code>cost</code> function.</p><p>Inputs:</p><ul><li><code>stats::Dict{Symbol,DataFrame}</code>: pairs of <code>:solver =&gt; df</code>;</li><li><code>cost::Function</code>: cost function applyed to each <code>df</code>. Should return a vector with the cost of solving the problem at each row;<ul><li>0 cost is not allowed;</li><li>If the solver did not solve the problem, return Inf or a negative number.</li></ul></li></ul><p>Examples of cost functions:</p><ul><li><code>cost(df) = df.elapsed_time</code>: Simple <code>elapsed_time</code> cost. Assumes the solver solved the problem.</li><li><code>cost(df) = (df.status .!= :first_order) * Inf + df.elapsed_time</code>: Takes into consideration the status of the solver.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.profile_solvers" href="#SolverBenchmark.profile_solvers"><code>SolverBenchmark.profile_solvers</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">p = profile_solvers(stats, costs, costnames)</code></pre><p>Produce performance profiles comparing <code>solvers</code> based on the data in <code>stats</code>.</p><p>Inputs:</p><ul><li><code>stats::Dict{Symbol,DataFrame}</code>: a dictionary of <code>DataFrame</code>s containing the   benchmark results per solver (e.g., produced by <code>bmark_results_to_dataframes()</code>)</li><li><code>costs::Vector{Function}</code>: a vector of functions specifying the measures to use in the profiles</li><li><code>costnames::Vector{String}</code>: names to be used as titles of the profiles.</li></ul><p>Keyword inputs:</p><ul><li><code>width::Int</code>: Width of each individual plot (Default: 400)</li><li><code>height::Int</code>: Height of each individual plot (Default: 400)</li></ul><p>Output: A Plots.jl plot representing a set of performance profiles comparing the solvers. The set contains performance profiles comparing all the solvers together on the measures given in <code>costs</code>. If there are more than two solvers, additional profiles are produced comparing the solvers two by two on each cost measure.</p></div></section><section><div><pre><code class="language-none">p = profile_solvers(results)</code></pre><p>Produce performance profiles based on <code>PkgBenchmark.benchmarkpkg</code> results.</p><p>Inputs:</p><ul><li><code>results::BenchmarkResults</code>: the result of <code>PkgBenchmark.benchmarkpkg()</code>.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.profile_package" href="#SolverBenchmark.profile_package"><code>SolverBenchmark.profile_package</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">p = profile_package(judgement)</code></pre><p>Produce performance profiles based on <code>PkgBenchmark.BenchmarkJudgement</code> results.</p><p>Inputs:</p><ul><li><p><code>judgement::BenchmarkJudgement</code>: the result of, e.g.,</p><pre><code class="language-none">commit = benchmarkpkg(mypkg)  # benchmark a commit or pull request
master = benchmarkpkg(mypkg, &quot;master&quot;)  # baseline benchmark
judgement = judge(commit, master)</code></pre></li></ul></div></section></article><h2 id="Formatting-1"><a class="docs-heading-anchor" href="#Formatting-1">Formatting</a><a class="docs-heading-anchor-permalink" href="#Formatting-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.LTXformat" href="#SolverBenchmark.LTXformat"><code>SolverBenchmark.LTXformat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">LTXformat(x)</code></pre><p>Format <code>x</code> according to its type. For types <code>Signed</code>, <code>AbstractFloat</code>, <code>AbstractString</code> and <code>Symbol</code>, use a predefined formatting string passed to <code>@sprintf</code> and then the corresponding <code>safe_latex_&lt;type&gt;</code> function.</p><p>For type <code>Missing</code>, return &quot;NA&quot;.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.MDformat" href="#SolverBenchmark.MDformat"><code>SolverBenchmark.MDformat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">MDformat(x)</code></pre><p>Format <code>x</code> according to its type. For types <code>Signed</code>, <code>AbstractFloat</code>, <code>AbstractString</code> and <code>Symbol</code>, use a predefined formatting string passed to <code>@sprintf</code>.</p><p>For type <code>Missing</code>, return &quot;NA&quot;.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.safe_latex_AbstractFloat" href="#SolverBenchmark.safe_latex_AbstractFloat"><code>SolverBenchmark.safe_latex_AbstractFloat</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>safe_latex_AbstractFloat(s)</code></p><p>For floats. Bypasses <code>Inf</code> and <code>NaN</code>. Enclose both the mantissa and the exponent in <code>\(</code> and <code>\)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.safe_latex_AbstractString" href="#SolverBenchmark.safe_latex_AbstractString"><code>SolverBenchmark.safe_latex_AbstractString</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>safe_latex_AbstractString(s)</code></p><p>For strings. Replaces <code>_</code> with <code>\_</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.safe_latex_Signed" href="#SolverBenchmark.safe_latex_Signed"><code>SolverBenchmark.safe_latex_Signed</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>safe_latex_Signed(s)</code></p><p>For signed integers. Encloses <code>s</code> in <code>\(</code> and <code>\)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverBenchmark.safe_latex_Symbol" href="#SolverBenchmark.safe_latex_Symbol"><code>SolverBenchmark.safe_latex_Symbol</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>safe_latex_Symbol(s)</code></p><p>For symbols. Same as strings.</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 12 April 2020 22:58">Sunday 12 April 2020</span>. Using Julia version 1.1.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
